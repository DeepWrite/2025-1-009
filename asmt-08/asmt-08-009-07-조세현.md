---
title: 009-07 조세현 (과제-08)
layout: home
nav_order: 07
parent: 과제-08 기말과제 초고 작성하기
permalink: /asmt-08/009-07
---

# (초고) 과제-08 기말과제 초고 작성하기 009-07 조세현 

# 제목: AI 생성물 표시 의무, 기술적 완전성이 결여되어도 입법은 정당화될 수 있는가?

## 서론

생성형 인공지능(Generative AI)의 발전은 텍스트, 이미지, 영상 등 인간의 창작과 구별이 어려운 콘텐츠를 빠르게 확산시키고 있다. 이에 따라, AI가 생성한 결과물을 명확히 식별하고 구분할 수 있는 법적 기준을 마련해야 한다는 주장이 힘을 얻고 있다(Zakir et al. 2024, p. 2522). 그러나 AI 생성 여부를 정확히 판별할 수 없는 상황에서 이를 규제하려는 시도는 자칫 혁신을 저해하고 경제에 악영향을 미칠 수 있다는 우려가 제기될 수 있다(홍석한 2022, p. 270). 검출 기술이 미비하다는 이유로, 입법 자체를 보류해야 한다는 것이다.

하지만 과연 기술적 완전성이 확보되기 전에는 아무런 법적 조치를 취할 수 없는 것일까? 본 논증문은 그러한 주장에 반대하며, AI 생성물의 표시 의무 입법은 검출 기술의 불완전함에도 불구하고 충분히 정당화될 수 있다고 주장한다. 법은 단지 사법적 판단을 위한 도구뿐만이 아니라, 사회적 신호와 사전 예방이라는 역할을 수행하며, 그 자체로서 규범적 효과를 가지기 때문이다. 즉 기술적 완전성이 결여되어 있음에도 불구하고, AI 생성물에 대한 명확한 표기 기준을 제시하는 입법은 향후 기술 발전에 따른 규제 기반을 마련할 뿐만 아니라 현재의 불확실한 상황에서 최소한의 질서를 제공하는 방식으로 기능할 수 있다.

## 본론

### AI 생성물 규제 미비의 문제점

AI 생성물 규제 미비는 실질적 피해로 이어지고 있다. 가짜뉴스, 딥페이크, 허위 학술 출판물 등은 이미 언론, 정치, 금융 등 다양한 영역에서 파급력을 보이고 있으며(Chesney and Citron 2019, p. 1767), 이는 단지 '기술적 문제'가 아니라 '사회적 비용'의 문제다. 특히 교육기관이나 저널리즘, 학계 등에서는 AI 생성물의 무표기 혼용이 진위 판단을 어렵게 하고, 결과적으로 수용자의 판단 부담을 증가시킨다.

### 입법의 사회적 신호 기능: 법은 경고이자 행동 기준이다

법은 단순히 행위를 금지하거나 허용하는 기술적 장치가 아니라, 사회가 바람직하게 여기는 행동 기준을 구성원들에게 명확히 제시하는 규범적 기제다(양선숙 2012, p. 42). AI 생성물 표시 의무 입법은 법이 사회에 전달하는 규범적 신호의 한 형태로, 인간 창작물과 AI 생성물이 혼재된 현실에서 최소한의 구분 기준을 제시한다. 그러므로, AI 생성물 표시 의무 입법은 검출 기술의 완전성과 무관하게 사회적 신호 기능을 수행할 수 있다.
이 원칙에 따르면, 법은 기술적 입증 가능성과 별개로 사회적 행동 양식에 영향을 미칠 수 있다. 예를 들어, AI 생성물 표시 의무가 법제화될 경우, 이는 단순히 사후적 처벌을 위한 규정이 아니라, 모든 이해관계자에게 “AI 생성물은 반드시 표시해야 한다”는 사회적 기준을 선제적으로 제시하는 역할을 한다.
EU AI Act의 사례처럼, 명확한 검출 체계가 완비되지 않았음에도 불구하고 ‘고위험 콘텐츠’에 대한 표시·분류 기준을 마련해둔 것은 이러한 사회적 신호 기능에 기반한다(홍석한 2022, pp. 251-263). 따라서 검출 기술이 완전하지 않더라도, 입법은 가능하며 오히려 필요하다.
이는 EU GDPR(2018)의 입법 과정에서도 유사하게 나타났다. 당시 개인정보 위반 탐지 기술이 불완전했음에도 불구하고, 유럽연합은 입법을 통해 최소한의 기준과 절차를 정하고, 그 위에 후속 기술 발전과 제도 개선을 이어갔다. AI 생성물에 대해서도 법이 먼저 경고를 보내고, 기술과 산업이 그에 호응해 발전하는 선순환을 설계할 수 있다.

### 기술적 미비는 규제 도입의 시점과 방식에 영향을 줄 뿐, 입법 자체를 가로막지는 않는다

AI 생성물의 표시를 의무화하자는 주장은 기술적으로 '100% 판별 가능'하다는 가정에서 출발하지 않는다. 오히려 현재의 기술적 불완전성, 즉 인간과 AI의 창작물을 구분하기 어려운 상황을 인정하는 데에서 시작한다. 
AI는 확률 기반의 언어 모델로 작동하며, 기존 데이터를 학습해 유사한 패턴을 생성하기 때문에 명확한 창작 기원이 드러나지 않는다. AI 생성 여부를 구분하는 기술이 완벽하지 않다는 점은 명백하다. 생성형 AI 모델은 확률적 분포에 따라 결과물을 생성하는데, 생성 기술이 발전함에 따라 AI 기반 생성물과 인간 창작물의 구별이 점점 어려워지고 있다. 현재의 AI 텍스트 감지 기술은 여전히 확률적 판단에 의존하고 있고, 워터마킹 기법과 추론 기반 감지기 모두 회피 가능성과 불확실성으로 인해 법적 판단에 사용하기에는 한계가 크다(Fariello et al. 2024, pp. 1-12). 특히 인간이 AI 생성 텍스트를 재구성하거나 스타일을 혼합할 경우 탐지가 사실상 불가능하다.
하지만 이것이 곧 입법을 포기해야 한다는 결론으로 이어지는 것은 아니다. 법은 기술적 완성도를 기준으로 시행 시점을 유예하거나, 일단 기본 원칙만을 정한 후 시행령 등을 통해 구체화를 유보하는 방식으로 유연하게 설계될 수 있다. 중요한 것은 사회적 논의와 규범적 기준을 마련하는 “입법 선언” 그 자체다. 따라서 법은 과학이 따라올 수 있는 속도보다 앞서 ‘예방적 기준’을 설정할 수 있어야 하며, 특히 “경고, 투명성, 주의 의무”와 같은 비형벌적 조치들은 기술적 미비를 이유로 미룰 필요가 없다.

### 불완전한 법은 자의적 집행과 표현의 자유 침해를 낳는다?

“AI 생성물 여부를 정확히 검출할 수 없다면, 법을 적용하는 과정에서 무고한 사람에게 과도한 책임이 돌아갈 수 있으며, 이는 표현의 자유를 침해한다.”는 반론이 제기될 수 있다. 합리적인 규범은 시민들이 법 아래에서 평등하게 대우받고 예측 가능하게 처벌되며, 자의적 판단 없이 적용될 수 있어야 하기 때문에(Waldron et al. 2023) 이러한 입장은 타당한 문제의식을 제기하지만, 이로 인해 입법 전체를 중단해야 한다는 결론은 비약적이다.

표시 의무 입법은 자의적 집행이나 표현의 자유 침해로 논리적으로 귀결되지 않는다. 그 이유는 다음과 같다.
첫째, 표시 의무 입법의 핵심은 형사처벌이 아닌 투명성 강화와 정보 제공에 있다. 실제로 EU AI Act 등 주요 입법안은 AI 생성물의 표시를 의무화하면서도, 그 집행 방식에서 ‘투명성’과 ‘알 권리’의 실현에 초점을 맞추고 있다(홍석한 2022, p. 255). 이는 사용자의 자율적 판단을 보장하는 장치로 작동하며, 입법 목적이 표현의 자유를 제한하는 데 있지 않음을 명확히 한다.
둘째, 기술적 불완전성으로 인해 집행 과정에서 자의적 판단이 발생할 수 있다는 우려는, 입법 설계 단계에서 충분히 완화될 수 있다. 예를 들어, EU AI Act는 기술의 발전에 따른 유연한 대응, 상황에 적합한 비례적인 규율과 탄력성 확보를 추구한다(홍석한 2022, p. 268). 또한, 실제 법 집행에서는 “합리적으로 인지 가능한 범위 내에서” 표시 의무를 부과함으로써, 기술적 한계로 인한 과도한 책임 전가를 방지한다.

결국, 표시 의무 입법이 기술적 불완전성 때문에 자의적 집행이나 표현의 자유 침해로 귀결된다는 주장은 논리적 비약이다. 

## 결론

AI 생성물에 대한 표시 의무 입법은 기술적 완전성이 결여되어 있다는 이유만으로 정당성을 상실하지 않는다. 법은 단지 기술을 뒷받침하는 도구가 아니라, 사회가 바람직하다고 여기는 질서와 기준을 선제적으로 제시하는 규범적 선언이기도 하다. 따라서 기술적 불완전성은 입법의 유예 사유가 아니라, 오히려 입법이 요구되는 하나의 정당화 조건이 될 수 있다. 
또한 기술 발전과 법적 기준의 상호작용은 역사적으로 입증된 선순환 구조다. EU AI Act의 사례에서 볼 수 있듯, 불완전한 기술 환경에서의 입법은 오히려 혁신을 유도하고 법적 명확성을 확보한다.
오늘날과 같은 과도기적 상황에서는, 법이 사회에 “무엇이 책임 있는 창작인가”라는 기준을 먼저 제시함으로써 기술과 산업의 방향성을 정렬시켜야 한다. 이는 법이 가진 신호적·예방적 기능을 통해 가능하며, 이러한 기능은 과학적 검증이나 완전한 검출 기술을 전제로 하지 않는다. 그렇기에 지금 필요한 것은 처벌 중심의 엄격한 규제가 아니라, 표시 의무와 같은 ‘비형벌적·선제적 조치’를 통해 사회적 기준을 세우는 것이다. 
결국 AI 생성물 표시 입법은 기술적 완전성을 기다릴 필요 없이 사회 전체의 질서와 신뢰를 지키기 위한 선제적 규범 선언으로서 정당성을 가진다.

## 참고문헌

### 국내문헌

> 홍석한. (2022). 유럽연합'인공지능법안'의 주요 내용과 시사점. 유럽헌법연구, (38), 243-282.
> 양선숙. (2012). 법, 규범성, 그리고 규칙 준수의 동기에 대한 관행론적 이해. 법철학연구, 15(3), 41-74.

### 외국 문헌

> Zakir, M. H., Bashir, S., Nisar, K., Ibrahim, S., Khan, N., & Khan, S. H. (2024). Navigating the Legal Labyrinth: Establishing Copyright Frameworks for AI-Generated Content. Remittances Review, 9(1), 2515-2532.
> Chesney, B., & Citron, D. (2019). Deep fakes: A looming challenge for privacy, democracy, and national security. Calif. L. Rev., 107, 1753-1819.
> EU GDPR. (2018, May). General data protection regulation (gdpr).
> Fariello, S., Fenza, G., Forte, F., Gallo, M., & Marotta, M. (2024). Distinguishing human from machine: a review of advances and challenges in ai-generated text detection. International Journal of Interactive Multimedia and Artificial Intelligence, 8(5), 1-12.
> Waldron, J. (2023). The rule of law. In E. N. Zalta & U. Nodelman (Eds.), The Stanford Encyclopedia of Philosophy (Fall 2023 Edition). Metaphysics Research Lab, Stanford University. https://plato.stanford.edu/archives/fall2023/entries/rule-of-law/