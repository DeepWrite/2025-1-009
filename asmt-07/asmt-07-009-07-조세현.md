---
title: 009-07 조세현 (과제-07)
layout: home
nav_order: 07
parent: 과제-07 개인별 논증 구조 작성하기
permalink: /asmt-07/009-07
---

# 과제-07 개인별 논증 구조 작성하기 009-07 조세현

## 제목: AI 생성물에 대한 저작권 규제는 기술적으로 AI 사용 여부가 검증 가능할 때에만 정당성을 가질 수 있다  

## 1. 쟁점과 딜레마

| 구분 | 내용 |
|:---|:---|
| 주제(Topic) | AI 생성물에 대한 저작권 규제의 정당성 문제 |
| 도전하려는 쟁점 | 기술적 검증이 불가능한 상황에서 규제가 정당한가 |
| 딜레마/난제 | 규제를 하면 임의적 집행의 위험이 존재하고, 규제를 하지 않으면 저작권이 무력화될 위험이 존재한다. |
| 딜레마/난제 해소/해결 방법 | 법적 정당성은 규범적 기준에 따라 판단되어야 하며, 기술적 불확실성은 그 정당성을 훼손함 |

① 주제(Topic): AI 생성물에 대한 저작권 규제는 기술적으로 AI 사용 여부가 검증 가능할 때에만 정당성을 가질 수 있다.

② 도전하는 학술적 쟁점: AI 기술의 발전으로 인간 창작물과 AI 생성물의 경계가 모호해졌고, 이에 따라 다음과 같은 질문이 제기된다. 

- **AI 사용 여부를 기술적으로 검증할 수 없는 상황에서, 특정 창작물을 규제 대상으로 삼는 것이 공정한가?**  
- **입법이 정당성을 가지려면 기술적·윤리적 기반 중 어느 쪽이 우선되는가?**  
- **검증 불가능성 하에서의 법은 자의적 집행과 차별적 적용을 피할 수 있는가?**

③ 유발되는 딜레마 또는 난제

- 딜레마 구조
  - **(A)** AI 사용에 대한 규제가 없으면, 창작자 권리가 침해되고 저작권 제도 자체가 무력화될 수 있다.
  - **(B)** 그러나 기술적으로 AI 사용 여부를 검증할 수 없다면, 규제는 자의적이고 불공정하게 적용될 위험이 크며, 이는 법의 정당성을 훼손한다.

④ 딜레마 해소 (또는 난제 해결) 전략

- 입법의 정당성은 단순한 정책 효과성이 아니라, 공정성, 투명성, 일관성이라는 규범적 기준을 충족해야 한다. (Waldron et al., 2023)
- 기술적으로 검증이 불가능한 특성을 대상으로 한 규제는 필연적으로 자의적 집행을 초래하며, 이는 법의 근본적 정당성을 약화시킨다.
- 따라서, 검증 가능성 확보 전에는 AI 생성물 규제는 정당한 법적 규범이 될 수 없으며, 임시적 대응보다 기술 기반의 투명한 제도 정비가 우선되어야 한다.

## 2. 논증구조

### 기본구조

- **논제:** AI 생성물에 대한 법적 규제는 기술적 검증 가능성이 확보되지 않으면 정당성을 가질 수 없다.
  - **전제1:** 법적 규제의 정당성은 규범적 원칙(공정성, 비차별성, 일관성 등)에 기반해야 한다.
    - 합법적인 규범은 단순한 집행 가능성이 아니라, 시민들이 법 아래에서 평등하게 대우받고 예측 가능하게 처벌되며, 자의적 판단 없이 적용될 수 있어야 한다(Waldron et al., 2023).
  - **전제2:** AI 사용 여부는 현 기술 수준에서 신뢰할 수 있는 방식으로 검증되기 어렵다.
    - AI 기반 생성물은 인간 창작물과의 구별이 점점 어려워지고 있으며, 현재의 AI 텍스트 감지 기술은 여전히 확률적 판단에 의존하고 워터마킹 기법과 추론 기반 감지기 모두 회피 가능성과 불확실성으로 인해 법적 판단에 사용하기에는 한계가 크다(Fariello et al., 2024).
    - 특히, 인간이 AI 생성 텍스트를 재구성하거나 스타일을 혼합할 경우 탐지가 사실상 불가능하다.
  - **전제3:** 검증이 불가능한 사실에 기반한 법률은 자의적 적용과 불공정한 집행을 초래하게 된다.
      - 법이 어떤 대상에게는 AI 사용을 인정하고, 다른 유사한 대상에게는 그렇지 않다고 판정한다면 이는 법 앞의 평등 원칙을 위반하며, 임의적 판단의 위험을 수반하게 된다.
      - 이처럼 법적 기준이 불투명하거나 일관되지 않으면, 시민은 법을 예측하거나 자율적으로 준수하기 어렵고, 이는 법 제도 자체에 대한 신뢰를 훼손한다.
- **결론:** 따라서, AI 생성 여부가 기술적으로 검증 불가능한 현재의 상황에서, AI 생성물에 대한 법적 규제는 규범적 정당성을 갖기 어렵다.

### 예상반론과 재반박

- **예상반론(연역적 논증의 타당성 공격):** **전제2**에서 말하는 “기술적 검증 불가능성”은 일시적인 현상일 뿐이며, 워터마킹 등 다양한 추적 기술이 빠르게 발전하고 있으므로, 법적 규제는 미리 마련해둘 필요가 있다.
  - 논리적 취약점 지적: 연역적 논증에서 규제의 "현재 정당성"을 논할 때, "미래의 가능성"은 정당성의 근거가 될 수 없다. 현재 검증이 불가능한 상태에서 제정된 규제는 자의성과 불공정성을 내포할 수 있으며, 이는 법적 정당성의 핵심 원칙에 위배된다.

- **재반박:** 규제는 단지 미래 가능성에 기대어 설계될 수 없으며, 현재의 조건 하에서 예측 가능하고 공정한 집행이 가능한가에 따라 정당성이 평가되어야 한다. 기술이 불완전한 상태에서 마련된 규제는 결과적으로 시민의 권리를 임의로 제한하는 위험이 있으며, 이는 법 제도의 근간을 훼손할 수 있다. 따라서 기술적 검증 가능성이 확보되기 전에는 규제 도입이 유예되어야 한다.

## 참고문헌

- Waldron, J. (2023). The rule of law. In E. N. Zalta & U. Nodelman (Eds.), The Stanford Encyclopedia of Philosophy (Fall 2023 Edition). Metaphysics Research Lab, Stanford University. https://plato.stanford.edu/archives/fall2023/entries/rule-of-law/
- Fariello, S., Fenza, G., Forte, F., Gallo, M., & Marotta, M. (2024). Distinguishing human from machine: a review of advances and challenges in ai-generated text detection. International Journal of Interactive Multimedia and Artificial Intelligence, 8(5), 1-12.